{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T18:56:24.095835Z","iopub.status.busy":"2021-11-13T18:56:24.095465Z","iopub.status.idle":"2021-11-13T18:56:33.954553Z","shell.execute_reply":"2021-11-13T18:56:33.953775Z","shell.execute_reply.started":"2021-11-13T18:56:24.095756Z"},"trusted":true},"outputs":[],"source":["#installing required libraries\n","!pip install openpyxl\n","\n","#importing required libraries\n","\n","import numpy as np \n","import pandas as pd "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T18:56:53.407578Z","iopub.status.busy":"2021-11-13T18:56:53.406805Z","iopub.status.idle":"2021-11-13T18:56:54.159229Z","shell.execute_reply":"2021-11-13T18:56:54.158436Z","shell.execute_reply.started":"2021-11-13T18:56:53.407535Z"},"trusted":true},"outputs":[],"source":["#reading the dataset\n","# df = pd.read_excel(\"../input/auto-eval/Re-evaluated Automatic Research Stuff.xlsx\", \"Endsem G1 Q7\", usecols=[0,2,5,6,7], engine=\"openpyxl\")\n","# df = pd.read_excel(\"../input/auto-eval/Re-evaluated Automatic Research Stuff.xlsx\", \"Q11\", usecols=[0,3,5,6,7], engine=\"openpyxl\")\n","df_tutorial1 = pd.read_excel(\"../input/auto-eval/Tutorial 1_corrected(1-1174) - Re Eval.xlsx\", \"Q7\", usecols=[0,3,5,7], engine=\"openpyxl\")\n","\n","# df.columns =['username', 'Explanation for question 11 here', 'Rationale(1.5)', 'Assigned Points - Anjali', 'Assigned Points - Sanskriti']\n","df_tutorial1.columns =['username', 'Explanation for question 11 here', 'Rationale(1.5)', 'Assigned Points - Ranjani']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Pre Processing"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T18:58:00.047467Z","iopub.status.busy":"2021-11-13T18:58:00.046821Z","iopub.status.idle":"2021-11-13T18:58:00.074650Z","shell.execute_reply":"2021-11-13T18:58:00.073900Z","shell.execute_reply.started":"2021-11-13T18:58:00.047422Z"},"trusted":true},"outputs":[],"source":["df_tutorial1.info()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T18:58:21.882957Z","iopub.status.busy":"2021-11-13T18:58:21.882264Z","iopub.status.idle":"2021-11-13T18:58:21.916359Z","shell.execute_reply":"2021-11-13T18:58:21.915691Z","shell.execute_reply.started":"2021-11-13T18:58:21.882899Z"},"trusted":true},"outputs":[],"source":["#remove data where no explanation is given\n","df_tutorial1[\"Explanation for question 11 here\"].replace(0, np.nan, inplace = True)\n","# df[\"Rationale(1.5)\"].replace(-1.5, 0, inplace = True)\n","# df[\"Rationale(1.5)\"].replace(-0.5, 1, inplace = True)\n","\n","cleaned_df_t1 = df_tutorial1.dropna()\n","#can create new column with punctuation removal to delete answers which only have symbols\n","\n","#remove word for word matches - obviously copied\n","cleaned_df_t1['Column1_lower'] = x['Explanation for question 11 here'].astype(str).str.lower()\n","cleaned_df_t1.drop_duplicates(subset = 'Column1_lower', keep = False, inplace = True)\n","cleaned_df_t1.drop('Column1_lower', axis=1, inplace=True)\n","\n","cleaned_df_t1.reset_index(inplace=True, drop=True)\n","cleaned_df_t1.info()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T18:58:25.504699Z","iopub.status.busy":"2021-11-13T18:58:25.504183Z","iopub.status.idle":"2021-11-13T18:58:25.525374Z","shell.execute_reply":"2021-11-13T18:58:25.524649Z","shell.execute_reply.started":"2021-11-13T18:58:25.504659Z"},"trusted":true},"outputs":[],"source":["cleaned_df_t1.groupby('Rationale(1.5)').count()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Text Vectorization - TF IDF"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T19:07:15.198052Z","iopub.status.busy":"2021-11-13T19:07:15.197517Z","iopub.status.idle":"2021-11-13T19:07:16.063209Z","shell.execute_reply":"2021-11-13T19:07:16.062409Z","shell.execute_reply.started":"2021-11-13T19:07:15.198008Z"},"trusted":true},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer()\n","text_vec = vectorizer.fit_transform(cleaned_df_t1[\"Explanation for question 11 here\"].astype(str))\n","print(text_vec.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Similarity Analysis"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T19:07:18.278262Z","iopub.status.busy":"2021-11-13T19:07:18.277693Z","iopub.status.idle":"2021-11-13T19:07:18.566622Z","shell.execute_reply":"2021-11-13T19:07:18.565910Z","shell.execute_reply.started":"2021-11-13T19:07:18.278221Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","similarities = cosine_similarity(text_vec,text_vec) #generates a diagonal matrix where each row is the cosine similairty of a given vector with each other tect vector\n","print(\"Mean:\",np.mean(similarities)) #average of similarity score across all vectors\n","print(\"Standard Deviation\",np.std(similarities)) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Visualisations"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T19:08:38.003134Z","iopub.status.busy":"2021-11-13T19:08:38.002563Z","iopub.status.idle":"2021-11-13T19:08:38.410908Z","shell.execute_reply":"2021-11-13T19:08:38.410195Z","shell.execute_reply.started":"2021-11-13T19:08:38.003096Z"},"trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import TruncatedSVD\n","\n","#used PCA to reduce the multi-dimensional text vector to 2-dimension to be able to plot it on a x-y plan\n","pca = PCA(n_components=2)\n","reduced_features = pca.fit_transform(text_vec)#.toarray())\n","svd = TruncatedSVD(n_components=2, random_state=42)\n","reduced_features = svd.fit_transform(text_vec) \n","\n","#visualising the text clusters based on colour coded assigned scores\n","color_dict = {-0.5:-2, -1.5:-1,  0.0:0, 0.5:1, 1.0:2, 1.5:3, 2.0:4,2.5:5,3.0:6}\n","classes = ['0','0.5', '1', '1.5']\n","scatter = plt.scatter(reduced_features[:,0], reduced_features[:,1],c = [color_dict[i] for i in x['Assigned Points - Ranjani']])\n","# plt.figure(figsize=(11, 8))\n","\n","plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n","plt.title(\"Q7 Tutorial 1 - Assigned Points Ranjani\")\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Clustering"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-11-13T19:08:45.079234Z","iopub.status.busy":"2021-11-13T19:08:45.078620Z","iopub.status.idle":"2021-11-13T19:08:45.647453Z","shell.execute_reply":"2021-11-13T19:08:45.646784Z","shell.execute_reply.started":"2021-11-13T19:08:45.079197Z"},"trusted":true},"outputs":[],"source":["# from sklearn.cluster import DBSCAN\n","# from sklearn.cluster import OPTICS\n","# from sklearn.cluster import KMeans\n","\n","def cluster(cluster_type, text_vec, minsamples=1, n_clusters=4, epsilon=0.25):\n","    preds = []\n","    if cluster_type == \"DBSCAN\":\n","        preds = DBSCAN(eps=epsilon,min_samples=minsamples).fit_predict(text_vec)\n","    elif cluster_type == \"OPTICS\":\n","        preds = OPTICS(min_samples=7).fit_predict(text_vec)\n","    elif cluster_type == \"K Means\":\n","        kmeans = KMeans(n_clusters=4, random_state=0).fit(text_vec)\n","        preds = kmeans.labels_\n","    return preds\n","\n","\n","titles = [\"DBSCAN\", \"OPTICS\", \"K Means\"]\n","\n","for title in titles:\n","    preds = cluster(title, text_vec)\n","    df_cleaned_t1['labels_'+title] = preds\n","\n","#plot the predictions - colour coded by cluster number\n","scatter = plt.scatter(reduced_features[:,0], reduced_features[:,1], c=preds)\n","plt.title(title + \" Clusters\")\n","plt.legend(handles=scatter.legend_elements()[0], labels=['0','1','2','3'])\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Summary Generation - Generate a summary of all answers in a cluster"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-08T16:43:07.959863Z","iopub.status.busy":"2021-11-08T16:43:07.959229Z","iopub.status.idle":"2021-11-08T16:43:07.963934Z","shell.execute_reply":"2021-11-08T16:43:07.963027Z","shell.execute_reply.started":"2021-11-08T16:43:07.959825Z"},"trusted":true},"outputs":[],"source":["!pip install bert-extractive-summarizer\n","!pip install neuralcoref\n","!pip install spacy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-08T17:23:03.117308Z","iopub.status.busy":"2021-11-08T17:23:03.116937Z","iopub.status.idle":"2021-11-08T17:23:38.932182Z","shell.execute_reply":"2021-11-08T17:23:38.931598Z","shell.execute_reply.started":"2021-11-08T17:23:03.117264Z"},"trusted":true},"outputs":[],"source":["from summarizer import Summarizer\n","\n","# model = Summarizer()\n","\n","body1 = ''\n","body2 = ''\n","body3 = ''\n","body4 = ''\n","for i in range(len(x)):\n","    if x.iloc[i]['labels_'+title] == 0:\n","        body1 = body1 + \" \" + str(x.iloc[i]['Explanation for question 11 here'])\n","    elif x.iloc[i]['labels_'+title] == 1:\n","        body2 = body2 + \" \" + str(x.iloc[i]['Explanation for question 11 here'])\n","    elif x.iloc[i]['labels_'+title] == 2:\n","        body3 = body3 + \" \" + str(x.iloc[i]['Explanation for question 11 here'])\n","    elif x.iloc[i]['labels_'+title] == 3:\n","        body4 = body4 + \" \" + str(x.iloc[i]['Explanation for question 11 here'])\n","    elif x.iloc[i]['labels_'+title] == -1:\n","        body4 = body4 + \" \" + str(x.iloc[i]['Explanation for question 11 here'])\n","\n","result1 = model(body1,num_sentences=5)\n","result2 = model(body2,num_sentences=5)\n","result3 = model(body3,num_sentences=5)\n","result4 = model(body4,num_sentences=5)\n","\n","file = open(\"temp_summaries_\"+title+\".txt\", \"w\")\n","file.write(\"SUMMARY 0\\n\")\n","file.write(result1 +\"\\n\\n\")\n","file.write(\"SUMMARY 1\\n\")\n","file.write(result2 +\"\\n\\n\")\n","file.write(\"SUMMARY 2\\n\")\n","file.write(result3 +\"\\n\\n\")\n","file.write(\"SUMMARY 3/-1\\n\")\n","file.write(result4 +\"\\n\\n\")\n","file.close()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Summary Analysis - Kappa Score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-08T17:28:20.832603Z","iopub.status.busy":"2021-11-08T17:28:20.831748Z","iopub.status.idle":"2021-11-08T17:28:20.841048Z","shell.execute_reply":"2021-11-08T17:28:20.840002Z","shell.execute_reply.started":"2021-11-08T17:28:20.832554Z"},"trusted":true},"outputs":[],"source":["#assigning a score to each Summary\n","assigned_score = []\n","for i in x['labels_'+title]:\n","    #print(i)\n","    if i == 0:\n","        assigned_score.append(0.5)\n","    elif i == 1:\n","        assigned_score.append(1.5)\n","    elif i == 2:\n","        assigned_score.append(1)\n","    else:\n","        assigned_score.append(0)\n","\n","x[title+'_assigned_score'] = assigned_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-08T17:29:44.436896Z","iopub.status.busy":"2021-11-08T17:29:44.436229Z","iopub.status.idle":"2021-11-08T17:29:44.454165Z","shell.execute_reply":"2021-11-08T17:29:44.453391Z","shell.execute_reply.started":"2021-11-08T17:29:44.436858Z"},"trusted":true},"outputs":[],"source":["#find kappa score to assess if the assigned scores agree with human evaluated scores\n","from sklearn.metrics import cohen_kappa_score\n","\n","cohen_kappa_score(df_cleaned_t1['Assigned Points - Ranjani'].astype(\"str\"), df_cleaned_t1['Rationale(1.5)'].astype(\"str\")) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
